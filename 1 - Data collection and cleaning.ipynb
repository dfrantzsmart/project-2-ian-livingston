{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c472b8915bc419c743ebcff76dbcf6e203ef99bf90689a3fba2566158d7e07a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Info\n",
    "In this notebook I've provided the primary code I used to collect data for this project and build my dataset. Most of it was scraped from a handful of sites, each noted below. My workflow was not linear and so I've pieced this together as best I can, and hopefully in a way that can be reasonably understood by anyone reading it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from fake_useragent import UserAgent\n",
    "import pickle\n",
    "\n",
    "# I built and ran the below functions direcectly in my scratch notebooks and cannot in this context import them correctly.\n",
    "# All referenced functions are viewable in the included simpsons_data_functions.py file\n",
    "\n",
    "import simpsons_data_functions"
   ]
  },
  {
   "source": [
    "## Scraping and cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = {'User-agent': ua.random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = get_simpsons_data([i for i in range(1, 31)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at season mean\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "enmax_palette = [\"#FFD99F\", \"#82CBEC\", \"#424F46\"]\n",
    "color_codes_wanted = ['simpsons_yellow', 'simpsons_blue', 'simpsons_black']\n",
    "c = lambda x: enmax_palette[color_codes_wanted.index(x)]\n",
    "plt.figure(figsize=(10, 4), dpi=200, frameon=False, edgecolor=\"white\")\n",
    "sns.barplot(x=\"Season\", y=\"Rating\", data=for_modeling, color=\"coral\", ci=None)\n",
    "plt.yticks(ticks=[5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10], size=9, color=\"black\")\n",
    "plt.ylim(5, 9.5)\n",
    "plt.ylabel(\"\", fontdict={\"fontsize\": 14, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.xticks(size=9, color=\"black\")\n",
    "plt.xlabel(\"\", fontdict={\"fontsize\": 14, \"color\": \"black\", \"weight\": \"black\"}, y=1.5);\n",
    "plt.text(-.32, 7.8, \"7.7\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(.67, 8.1, \"8.1\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(1.65, 8.25, \"8.2\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(2.66, 8.36, \"8.3\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(3.66, 8.44, \"8.4\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(4.66, 8.43, \"8.4\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(5.66, 8.42, \"8.4\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(6.66, 8.31, \"8.3\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(7.66, 7.86, \"7.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(8.65, 7.64, \"7.6\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(9.65, 7.31, \"7.3\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(10.64, 7.36, \"7.3\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(11.64, 7.11, \"7.1\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(12.64, 7.04, \"7.0\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(13.64, 6.95, \"6.9\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(14.64, 6.93, \"6.9\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(15.64, 6.82, \"6.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(16.64, 6.86, \"6.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(17.64, 6.86, \"6.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(18.63, 6.82, \"6.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(19.63, 6.74, \"6.7\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(20.63, 6.65, \"6.6\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(21.63, 6.815, \"6.8\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(22.63, 6.62, \"6.6\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(23.63, 6.615, \"6.6\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})\n",
    "plt.text(24.63, 6.58, \"6.6\", fontdict={\"fontsize\": 10, \"color\": \"black\", \"weight\": \"black\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at ratings in a countplot\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.countplot(x=\"Rating\", data=for_modeling);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning character names and viewing appearances\n",
    "\n",
    "all_character_appearances = []\n",
    "for ep in everything[\"Characters\"]:\n",
    "    for i in range(len(ep)):\n",
    "        all_character_appearances.append(ep[i])\n",
    "character_appearances_series = pd.Series(all_character_appearances, name=\"Character appearances\")\n",
    "character_appearances_series.replace(to_replace={\"(Homer)(.)*\": \"Homer Simpson\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(Grampa)(.)*\": \"Grampa Simpson\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(Abraham Simpson)(.)*\": \"Grampa Simpson\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Abe Simpson\": \"Grampa Simpson\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Barney\": \"Barney Gumble\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(Mont(.*))(.)*(Burns)\": \"Mr. Burns\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Carl Carlson\": \"Carl\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Lenny Leonard\": \"Lenny\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Otto Mann\": \"Otto\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(^Principal Seymour Skinner|^Skinner)\": \"Principal Skinner\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Seymour Skinner\": \"Principal Skinner\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Krusty\": \"Krusty the Klown\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Apu Nahasapeemapetilon\": \"Apu\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Waylon Smithers\": \"Smithers\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Gil Gunderson\": \"Gil\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Captain McCallister\": \"Sea Captain\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"The Sea Captain\": \"Sea Captain\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Captain Horatio McCallister\": \"Sea Captain\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Captain McAllister\": \"Sea Captain\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Kearney Zzyzwicz\": \"Kearney\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Moe\": \"Moe Szyslak\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(^Dr. Julius Hibbert|^Hibbert)\": \"Dr. Hibbert\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"(^Prof. Frink|^Frink)\": \"Professor Frink\"}, regex=True, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Ralph\": \"Ralph Wiggum\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Quimby\": \"Mayor Quimby\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Willie\": \"Groundskeeper Willie\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Groundskeeper WIllie\": \"Groundskeeper Willie\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Superintendant Chalmers\": \"Superintendent Chalmers\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Chalmers\": \"Superintendant Chalmers\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Charles Mr. Burns\": \"Mr. Burns\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Abraham 'Grampa Simpson\": \"Grampa Simpson\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Hans Moleman\": \"Moleman\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Maggie\": \"Maggie Simpson\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Chief Clancy Wiggum\": \"Chief Wiggum\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Ned\": \"Ned Flanders\"}, inplace=True)\n",
    "character_appearances_series.replace(to_replace={\"Officer Lou\": \"Lou\"}, inplace=True)\n",
    "\n",
    "character_appearances_df = pd.DataFrame(character_appearances_series.value_counts())\n",
    "character_appearances_df = character_appearances_df.reset_index()\n",
    "character_appearances_df.rename(columns={\"index\": \"Character\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting \"Airdate\" column to datetime and new column \"Year\"\n",
    "\n",
    "everything[\"Year\"] = everything[\"Airdate\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming writers column\n",
    "\n",
    "everything.rename(columns={\"Writers/directors\": \"Writing, etc., credits\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting episode writers as a single string\n",
    "\n",
    "new_writers_column = []\n",
    "for episode in list(everything[\"Writing, etc., credits\"]):\n",
    "    episode_writers = []\n",
    "    for person in episode:\n",
    "        for credit in writing_credits_list:\n",
    "            if credit in person:\n",
    "                episode_writers.append(person.split(\"(\")[0].strip())\n",
    "                break\n",
    "    new_writers_column.append(\", \".join(list(set(episode_writers))))\n",
    "\n",
    "everything[\"Written by\"] = new_writers_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded the CSV directly from Kaggle and then read it locally\n",
    " \n",
    "dialogue_lines = pd.read_csv(\"simpsons_script_lines.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing seasons\n",
    "\n",
    "dialogue_lines.sort_values(by=\"episode_id\")[\"episode_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-spoken lines, et.c, and renaming columns\n",
    "\n",
    "dialogue_lines.drop(columns=[\"raw_text\", \"spoken_words\", \"timestamp_in_ms\", \"id\", \"number\", \"location_id\", \"raw_location_text\"], inplace=True)\n",
    "dialogue_lines.rename(columns={\"speaking_line\": \"Speaking line\", \"episode_id\": \"Episode number\", \"character_id\": \"Character ID\", \"raw_character_text\": \"Character\", \"spoken_words\": \"Lines\", \"normalized_text\": \"Raw text\", \"word_count\": \"Word count\"}, inplace=True)\n",
    "dialogue_lines[\"Speaking line\"].replace(to_replace={\"true\": True, \"false\": False}, inplace=True)\n",
    "dialogue_lines = dialogue_lines[dialogue_lines[\"Speaking Line\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at what dialogue looks like for a single episode\n",
    "\n",
    "dialogue_lines[dialogue_lines[\"episode_id\"] == 52]\n",
    "homer_at_the_bat[\"word_count\"] = homer_at_the_bat[\"word_count\"].astype(int)\n",
    "total_words = homer_at_the_bat[\"word_count\"].sum()\n",
    "homer_at_the_bat[\"percentage_of_words\"] = homer_at_the_bat[\"word_count\"].apply(lambda x: (x*100)/total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column detailing whether an episode was a \"Treehouse of Horror\" episode\n",
    "# Note: I understand now that this should be done after splitting into training and testing sets\n",
    "\n",
    "everything[\"Treehouse of Horror?\"] = everything.index.str.contains(\"Treehouse of Horror\").astype(str)\n",
    "everything[\"Treehouse of Horror?\"].replace({\"False\": 0, \"True\": 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column detailing whether an episode was a season premiere or not\n",
    "# Note: I understand now that this should be done after splitting into training and testing sets\n",
    "\n",
    "everything[\"Season premier\"] = everything[\"Episode number\"] == 1\n",
    "everything[\"Season premier\"].replace(to_replace={True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns detailing whether an episode's main storylines included one of the \n",
    "# four main characters: Homer, Marge, Bart, and Lisa\n",
    "# Note: I understand now that this should be done after splitting into training and testing sets\n",
    "\n",
    "everything[\"Homer story\"] = everything[\"Description\"].str.contains(\"Homer\")\n",
    "everything[\"Homer story\"].replace(to_replace={True: 1, False: 0}, inplace=True)\n",
    "everything[\"Bart story\"] = everything[\"Description\"].str.contains(\"Bart\")\n",
    "everything[\"Bart story\"].replace(to_replace={True: 1, False: 0}, inplace=True)\n",
    "everything[\"Lisa story\"] = everything[\"Description\"].str.contains(\"Lisa\")\n",
    "everything[\"Lisa story\"].replace(to_replace={True: 1, False: 0}, inplace=True)\n",
    "everything[\"Marge story\"] = everything[\"Description\"].str.contains(\"Bart\")\n",
    "everything[\"Marge story\"].replace(to_replace={True: 1, False: 0}, inplace=True)\n",
    "everything[\"Milhouse story\"] = everything[\"Description\"].str.contains(\"Milhouse\")\n",
    "everything[\"Milhouse story\"].replace(to_replace={True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns detailing how writers are top-line credited for each episode\n",
    "\n",
    "writer_count_column = []\n",
    "for episode in list(everything[\"Writing, etc., credits\"]):\n",
    "    episode_writers = []\n",
    "    for person in episode:\n",
    "        for credit in writing_credits_list:\n",
    "            if credit in person:\n",
    "                episode_writers.append(person.split(\"(\")[0].strip())\n",
    "                break\n",
    "    writer_count_column.append(len(episode_writers))\n",
    "everything[\"Number of writers\"] = writer_count_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column detailing whether an episode was written by John Swartzwelder\n",
    "\n",
    "everything[\"Written by John Swartzwelder\"] = everything[\"Written by\"].str.contains(\"John Swartzwelder\")\n",
    "everything[\"Written by John Swartzwelder\"].replace(to_replace={True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling percentage of episode dialogue for each character in each episode\n",
    "\n",
    "homer_percentage = homer_series()\n",
    "bart_percentage = bart_series()\n",
    "lisa_percentage = lisa_series()\n",
    "marge_percentage = marge_series()\n",
    "moe_percentage = moe_series()\n",
    "milhouse_percentage = milhouse_series()\n",
    "mrburns_percentage = mrburns_series()\n",
    "grampa_percentage = grampa_series()\n",
    "flanders_percentage = flanders_series()\n",
    "skinner_percentage = skinner_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying main df into a new one with updated row\n",
    "\n",
    "new_everything = everything[:568]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns for each character's dialogue contribution as a percentage of the total.\n",
    "# In the case of the secondary characters, contribution is measured as a percentage of the \n",
    "# words not spoken by any of the four main characters.\n",
    "\n",
    "new_everything[\"Homer %\"] = [i/100 for i in homer_percentage]\n",
    "new_everything[\"Bart %\"] = [i/100 for i in bart_percentage]\n",
    "new_everything[\"Lisa %\"] = [i/100 for i in lisa_percentage]\n",
    "new_everything[\"Marge %\"] = [i/100 for i in marge_percentage]\n",
    "new_everything[\"Family total\"] = new_everything[\"Homer %\"] + new_everything[\"Marge %\"] + new_everything[\"Bart %\"] + new_everything[\"Lisa %\"]\n",
    "new_everything[\"Moe %\"] = [i/100 for i in moe_percentage]\n",
    "new_everything[\"Moe % v2\"] = [i/100 for i in moe_percentage] / (1 - new_everything[\"Family total\"])\n",
    "new_everything[\"Milhouse %\"] = [i/100 for i in milhouse_percentage]\n",
    "new_everything[\"Milhouse % v2\"] = [i/100 for i in milhouse_percentage] / (1 - new_everything[\"Family total\"])\n",
    "new_everything[\"Mr. Burns %\"] = [i/100 for i in mrburns_percentage]\n",
    "new_everything[\"Mr. Burns % v2\"] = [i/100 for i in mrburns_percentage] / (1 - new_everything[\"Family total\"])\n",
    "new_everything[\"Grampa %\"] = [i/100 for i in grampa_percentage]\n",
    "new_everything[\"Grampa % v2\"] = [i/100 for i in grampa_percentage] / (1 - new_everything[\"Family total\"])\n",
    "new_everything[\"Flanders %\"] = [i/100 for i in flanders_percentage]\n",
    "new_everything[\"Flanders % v2\"] = [i/100 for i in flanders_percentage] / (1 - new_everything[\"Family total\"])\n",
    "new_everything[\"Skinner %\"] = [i/100 for i in skinner_percentage]\n",
    "new_everything[\"Skinner % v2\"] = [i/100 for i in skinner_percentage] / (1 - new_everything[\"Family total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column that is distance from each episode's season mid-point\n",
    "\n",
    "dicto = new_everything.groupby(\"Season\")[\"Episode number\"].count().reset_index()\n",
    "dicto = dict(zip(dicto[\"Season\"], dicto[\"Episode number\"]))\n",
    "season_length_adj = []\n",
    "for value in dicto.values():\n",
    "    half = value / 2\n",
    "    for i in range(value):\n",
    "        season_length_adj.append(half)\n",
    "new_everything[\"Season mid_point\"] = season_length_adj\n",
    "new_everything[\"When in season\"] = np.abs((new_everything[\"Episode number\"] - new_everything[\"Season mid_point\"]) / new_everything[\"Season mid_point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting guest stars from TVDB\n",
    "\n",
    "guest_stars = guest_stars([i for i in range(27)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning out \"guest stars\" that have appeared many times Pamela Hayden, who does Milhouse, \n",
    "# Jimbo and Rod Flanders, has done > 600 episodes. Tress MacNeille, who does Agnes and\n",
    "# others, has appeared in > 550 episodes. Maggie Roswell, who does Helen Lovejoy, Maude Flanders \n",
    "# and Miss Hoover, has done > 200 episodes.\n",
    "\n",
    "for item in guest_stars:\n",
    "    if [] in item:\n",
    "        item.remove([])\n",
    "\n",
    "for item in guest_stars:\n",
    "    if 'Pamela Hayden' in item:\n",
    "        item.remove('Pamela Hayden')\n",
    "\n",
    "for item in guest_stars:\n",
    "    if 'Tress MacNeille' in item:\n",
    "        item.remove('Tress MacNeille')\n",
    "\n",
    "for item in guest_stars:\n",
    "    if 'Maggie Roswell' in item:\n",
    "        item.remove('Maggie Roswell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \"Number of Guest Stars\" column\n",
    "\n",
    "new_everything[\"Number of guest stars\"] = new_everything[\"Guest stars\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings/rater data from IMDB and creating columns for each segment\n",
    "\n",
    "ratings_data = get_imdb_ratings_info([i for i in range(1, 27)])\n",
    "rating_demos = []\n",
    "for season, data in ratings_data.items():\n",
    "    for name, ratings in data.items():\n",
    "        ep_list = []\n",
    "        for key, demos in ratings[1].items():\n",
    "            ep_list.append([key, demos])\n",
    "        rating_demos.append(ep_list)\n",
    "                \n",
    "all_raters = []\n",
    "male_raters = []\n",
    "female_raters = []\n",
    "for episode in rating_demos:\n",
    "    all_raters.append(episode[0])\n",
    "    male_raters.append(episode[1])\n",
    "    female_raters.append(episode[2])\n",
    "    \n",
    "all_raters_v2 = [episode[1] for episode in all_raters]\n",
    "male_raters_v2 = [episode[1] for episode in male_raters]\n",
    "female_raters_v2 = [episode[1] for episode in female_raters]\n",
    "all_all, all_minor, all_18_29, all_30_44, all_45_up = make_rater_columns(all_raters_v2)\n",
    "male_all, male_minor, male_18_29, male_30_44, male_45_up = make_rater_columns(male_raters_v2)\n",
    "female_all, female_minor, female_18_29, female_30_44, female_45_up = make_rater_columns(female_raters_v2)\n",
    "\n",
    "new_everything[\"All ratings\"] = all_all[:568]\n",
    "new_everything[\"<18 ratings\"] = all_minor[:568]\n",
    "new_everything[\"18-29 ratings\"] = all_18_29[:568]\n",
    "new_everything[\"30-44 ratings\"] = all_30_44[:568]\n",
    "new_everything[\"45+ ratings\"] = all_45_up[:568]\n",
    "\n",
    "new_everything[\"Male: All ratings\"] = male_all[:568]\n",
    "new_everything[\"Male: <18 ratings\"] = male_minor[:568]\n",
    "new_everything[\"Male: 18-29 ratings\"] = male_18_29[:568]\n",
    "new_everything[\"Male: 30-44 ratings\"] = male_30_44[:568]\n",
    "new_everything[\"Male: 45+ ratings\"] = male_45_up[:568]\n",
    "\n",
    "new_everything[\"Female: All ratings\"] = female_all[:568]\n",
    "new_everything[\"Female: <18 ratings\"] = female_minor[:568]\n",
    "new_everything[\"Female: 18-29 ratings\"] = female_18_29[:568]\n",
    "new_everything[\"Female: 30-44 ratings\"] = female_30_44[:568]\n",
    "new_everything[\"Female: 45+ ratings\"] = female_45_up[:568]\n",
    "\n",
    "# Parsing and removing the old columns (this was inefficient)\n",
    "\n",
    "new_everything[\"All: Number of ratings\"] = new_everything[\"All ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"All: Rating\"] = new_everything[\"All ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"All <18: Number of ratings\"] = new_everything[\"<18 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"All <18: Rating\"] = new_everything[\"<18 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"All 18-29: Number of ratings\"] = new_everything[\"18-29 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"All 18-29: Rating\"] = new_everything[\"18-29 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"All 30-44: Number of ratings\"] = new_everything[\"30-44 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"All 30-44: Rating\"] = new_everything[\"30-44 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"All 45+: Number of ratings\"] = new_everything[\"45+ ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"All 45+: Rating\"] = new_everything[\"45+ ratings\"].apply(lambda x: x[0])\n",
    "new_everything.drop(columns=[\"All ratings\", \"<18 ratings\", \"18-29 ratings\", \"30-44 ratings\", \"45+ ratings\"], inplace=True)\n",
    "\n",
    "new_everything[\"Male: Number of ratings\"] = new_everything[\"Male: All ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Male: Rating\"] = new_everything[\"Male: All ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Male <18: Number of ratings\"] = new_everything[\"Male: <18 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Male <18: Rating\"] = new_everything[\"Male: <18 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Male 18-29: Number of ratings\"] = new_everything[\"Male: 18-29 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Male 18-29: Rating\"] = new_everything[\"Male: 18-29 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Male 30-44: Number of ratings\"] = new_everything[\"Male: 30-44 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Male 30-44: Rating\"] = new_everything[\"Male: 30-44 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Male 45+: Number of ratings\"] = new_everything[\"Male: 45+ ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Male 45+: Rating\"] = new_everything[\"Male: 45+ ratings\"].apply(lambda x: x[0])\n",
    "new_everything.drop(columns=[\"Male: All ratings\", \"Male: <18 ratings\", \"Male: 18-29 ratings\", \"Male: 30-44 ratings\", \"Male: 45+ ratings\"], inplace=True)\n",
    "\n",
    "new_everything[\"Female: Number of ratings\"] = new_everything[\"Female: All ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Female: Rating\"] = new_everything[\"Female: All ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Female <18: Number of ratings\"] = new_everything[\"Female: <18 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Female <18: Rating\"] = new_everything[\"Female: <18 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Female 18-29: Number of ratings\"] = new_everything[\"Female: 18-29 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Female 18-29: Rating\"] = new_everything[\"Female: 18-29 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Female 30-44: Number of ratings\"] = new_everything[\"Female: 30-44 ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Female 30-44: Rating\"] = new_everything[\"Female: 30-44 ratings\"].apply(lambda x: x[0])\n",
    "new_everything[\"Female 45+: Number of ratings\"] = new_everything[\"Female: 45+ ratings\"].apply(lambda x: x[1])\n",
    "new_everything[\"Female 45+: Rating\"] = new_everything[\"Female: 45+ ratings\"].apply(lambda x: x[0])\n",
    "new_everything.drop(columns=[\"Female: All ratings\", \"Female: <18 ratings\", \"Female: 18-29 ratings\", \"Female: 30-44 ratings\", \"Female: 45+ ratings\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping TV viewership data first for seasons 1-20...\n",
    "# Source: https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes_(seasons_1%E2%80%9320)#Episodes\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes_(seasons_1%E2%80%9320)#Episodes\"\n",
    "response = requests.get(url, headers=user_agent)\n",
    "print(response.status_code)\n",
    "ratings_text = response.text\n",
    "ratings_soup = BeautifulSoup(ratings_text)\n",
    "\n",
    "viewers_per_episode = []\n",
    "episode_names = []\n",
    "for season in ratings_soup.find_all(\"table\", class_=\"wikitable plainrowheaders wikiepisodetable\"):\n",
    "    header_test = season.find(\"tr\")\n",
    "    if header_test.findNext(\"th\").text == \"Title\":\n",
    "        continue\n",
    "    for ep in season.find_all(\"tr\", class_=\"vevent\"):\n",
    "        episode_names.append((ep.find_all(\"td\")[1].text))\n",
    "        rating = (ep.find_all(\"td\")[6].text.split(\"[\")[0])\n",
    "        if rating == \"N/A\" or rating == \"TBD\":\n",
    "            viewers_per_episode.append(np.nan)\n",
    "        else:\n",
    "            print(rating)\n",
    "            viewers_per_episode.append(float(rating))\n",
    "\n",
    "# ...and then seasons 21-27\n",
    "# Source: # Source: https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes\"\n",
    "response = requests.get(url, headers=user_agent)\n",
    "print(response.status_code)\n",
    "ratings_text = response.text\n",
    "ratings_soup = BeautifulSoup(ratings_text)\n",
    "\n",
    "viewers_per_episode21_on = []\n",
    "episode_names21_on = []\n",
    "for season in ratings_soup.find_all(\"table\", class_=\"wikitable plainrowheaders wikiepisodetable\"):\n",
    "    header_test = season.find(\"tr\")\n",
    "    if header_test.findNext(\"th\").text == \"Title\":\n",
    "        continue\n",
    "    for ep in season.find_all(\"tr\", class_=\"vevent\"):\n",
    "        episode_names21_on.append((ep.find_all(\"td\")[1].text))\n",
    "        rating = (ep.find_all(\"td\")[6].text.split(\"[\")[0])\n",
    "        if rating == \"N/A\" or rating == \"TBD\":\n",
    "            viewers_per_episode21_on.append(np.nan)\n",
    "        else:\n",
    "            print(rating)\n",
    "            viewers_per_episode21_on.append(float(rating))\n",
    "\n",
    "viewers_per_episode.extend(viewers_per_episode21_on)\n",
    "new_everything[\"TV viewers\"] = viewers_per_episode[:568]"
   ]
  },
  {
   "source": [
    "### Dropping NaNs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_everything.dropna(inplace=True)"
   ]
  },
  {
   "source": [
    "### Dropping outlier \"Lisa Goes Gaga\" (3 std from mean with 3.9 rating)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_everything.drop(\"Lisa Goes Gaga\", inplace=True)"
   ]
  },
  {
   "source": [
    "## Pickling dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"simpsons_full.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(new_everything, to_write)"
   ]
  },
  {
   "source": [
    "## Feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \"Director mean\" column\n",
    "\n",
    "ratings_mean = new_everything[\"Rating\"].mean()\n",
    "ratings_std = new_everything[\"Rating\"].std()\n",
    "by_mean_rating = new_everything.groupby(\"Director\")[\"Rating\"].mean().reset_index()\n",
    "director_dict = {}\n",
    "for i in range(len(list(by_mean_rating[\"Director\"]))):\n",
    "    director_dict[by_mean_rating.iloc[i, 0]] = by_mean_rating.iloc[i, 1]\n",
    "director_by_mean = pd.DataFrame.from_dict(director_dict, orient='index')\n",
    "\n",
    "director_mean = director_by_mean.mean()\n",
    "director_std = director_by_mean.std()\n",
    "director_scores = (director_by_mean.loc[:, 0]-director_mean)/director_std\n",
    "new_everything[\"Director mean\"] = new_everything\"Director\"].replace(to_replace=director_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \"Season score\" column\n",
    " \n",
    "season_means = new_everything.groupby(\"Season\")[\"Rating\"].describe()[\"mean\"]\n",
    "season_scores = (season_means-season_means.describe().loc[\"mean\"])/season_means.describe().loc[\"std\"]\n",
    "score_dict = pd.Series.to_dict(season_scores)\n",
    "new_everything[\"Season score\"] = new_everything[\"Season\"].replace(to_replace=score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting secondary character dialogue percentages with \"Season score\"\n",
    "\n",
    "new_everything[\"Milhouse multiplied\"] = new_everything[\"Milhouse % v2\"] * new_everything[\"Season score\"]\n",
    "new_everything[\"Moe multiplied\"] = new_everything[\"Moe % v2\"] * new_everything[\"Season score\"]\n",
    "new_everything[\"Mr. Burns multiplied\"] = new_everything[\"Mr. Burns % v2\"] * new_everything[\"Season score\"]\n",
    "new_everything[\"Grampa multiplied\"] = new_everything[\"Grampa % v2\"] * new_everything[\"Season score\"]\n",
    "new_everything[\"Flanders multiplied\"] = new_everything[\"Flanders % v2\"] * new_everything[\"Season score\"]\n",
    "new_everything[\"Skinner multiplied\"] = new_everything[\"Skinner % v2\"] * new_everything[\"Season score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting \"Written by John Swartzwelder\" with \"Season score\"\n",
    "\n",
    "new_everything[\"John Swartzwelder multiplied\"] = new_everything[\"Written by John Swartzwelder\"] * new_everything[\"Season score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting \"Written by John Swartzwelder\" with \"Season score\"\n",
    "\n",
    "new_everything[\"Number of guest stars multiplied\"] = new_everything[\"Number of guest stars\"] * new_everything[\"Season score\"]"
   ]
  }
 ]
}